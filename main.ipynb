{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "train = np.load('feats.npy')\n",
    "train_labels = np.load('labels.npy')\n",
    "np.random.seed(42)\n",
    "theta = np.random.rand(15, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def inference(theta, feats):\n",
    "    \"\"\"make a prediction given a vector of features\"\"\"\n",
    "    eY = softmax(np.matmul(theta, feats))\n",
    "    return eY\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updatedPredictionMatrix(inference, label, feats):\n",
    "    \"\"\"creates matrix for updating theta based off of gradient of softmax + cross/entropy\"\"\"\n",
    "    inference[int(label)-1] = 1 - inference[int(label)-1]\n",
    "    return -5 * np.matmul(inference.reshape(len(inference), 1), np.column_stack(feats))\n",
    "\n",
    "def printLoss(inference, label):\n",
    "    \"\"\"print cross entropy loss, assuming actual y is one hot encoded\"\"\"\n",
    "    loss = -math.log(inference[int(label)-1])\n",
    "    print('Loss:', loss)\n",
    "    \n",
    "def loss(inference, label):\n",
    "    \"\"\"return cross entropy loss, assuming actual y is one hot encoded\"\"\"\n",
    "    try:\n",
    "        ans = -math.log(inference[int(label)-1])\n",
    "        return ans\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "def evalLoss(theta, train, label):\n",
    "    avgloss = 0\n",
    "    for x in range(len(train)):\n",
    "        los = loss(softmax(inference(theta, train[x])), label[x])\n",
    "#         pred = softmax(inference(theta, train[x]))\n",
    "        avgloss += los\n",
    "#         if (los > 3):\n",
    "#             print(los)\n",
    "#             qualitative(x, theta, train, label)\n",
    "    return avgloss / len(train)\n",
    "\n",
    "def evalAccuracy(theta, train, label):\n",
    "    correct = 0\n",
    "    for x in range(len(train)):\n",
    "        pred = np.argmax(softmax(inference(theta, train[x])))\n",
    "        if (pred == int(label[x])):\n",
    "            correct += 1\n",
    "    return round(correct / len(train), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_gradient_descent(theta, labels, train):\n",
    "    N = len(train)\n",
    "    updateM = np.zeros((15, 10000))\n",
    "    print(\"Beginning \", end = '')\n",
    "    y = np.linalg.norm(theta)\n",
    "    print(evalTrain(theta, train, labels))\n",
    "    for x in range(len(train)):\n",
    "        expY = inference(theta, train[x])\n",
    "        update = updatedPredictionMatrix(expY, labels[x], train[x])\n",
    "        if ( x % 1000 == 0):\n",
    "            print('Step', str(x)+'/'+str(N)+'  ')\n",
    "        update = np.add(update, updateM)\n",
    "    theta = np.add(theta, update)\n",
    "    print(\"End \", end='')\n",
    "    print(evalTrain(theta, train, labels))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in range(10):\n",
    "#     print(\"epoch\", x)\n",
    "#     theta = full_gradient_descent(theta, train_labels, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stochastic_descent(theta, labels, train):\n",
    "    N = len(train)\n",
    "    updateM = np.zeros((15, 10000))\n",
    "    y = np.linalg.norm(theta)\n",
    "    for x in range(100):\n",
    "        randSample = np.random.randint(0, train.shape[0])\n",
    "        expY = inference(theta, train[randSample]) #correct?\n",
    "        update = updatedPredictionMatrix(expY, labels[x], train[randSample])\n",
    "#             print('Step', str(x)+'/'+str(N)+'  ')\n",
    "        update = np.add(update, updateM)\n",
    "    theta = np.add(theta, update)\n",
    "    print(\"Loss: \", end='')\n",
    "    print(evalLoss(theta, train, labels))\n",
    "    print('Accuracy: ', str(evalAccuracy(theta, train, labels))+'%')\n",
    "    return theta\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Loss: 2.715930227582408\n",
      "Beginning epoch 0\n",
      "\n",
      "Loss: 2.721160163797172\n",
      "Accuracy:  0.062%\n",
      "\n",
      "Beginning epoch 1\n",
      "\n",
      "Loss: 2.7388231008936104\n",
      "Accuracy:  0.069%\n",
      "\n",
      "Beginning epoch 2\n",
      "\n",
      "Loss: 2.7278051753457477\n",
      "Accuracy:  0.0597%\n",
      "\n",
      "Beginning epoch 3\n",
      "\n",
      "Loss: 2.718367081363263\n",
      "Accuracy:  0.046%\n",
      "\n",
      "Beginning epoch 4\n",
      "\n",
      "Loss: 2.728201500486142\n",
      "Accuracy:  0.05%\n",
      "\n",
      "Beginning epoch 5\n",
      "\n",
      "Loss: 2.7142496823160056\n",
      "Accuracy:  0.0417%\n",
      "\n",
      "Beginning epoch 6\n",
      "\n",
      "Loss: 2.7228029554452786\n",
      "Accuracy:  0.0407%\n",
      "\n",
      "Beginning epoch 7\n",
      "\n",
      "Loss: 2.723886766647392\n",
      "Accuracy:  0.0327%\n",
      "\n",
      "Beginning epoch 8\n",
      "\n",
      "Loss: 2.7124039521952876\n",
      "Accuracy:  0.0277%\n",
      "\n",
      "Beginning epoch 9\n",
      "\n",
      "Loss: 2.7063494450094456\n",
      "Accuracy:  0.0467%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Beginning Loss: \", end = '')\n",
    "print(evalLoss(theta, train, train_labels))\n",
    "for x in range(10):\n",
    "    print(\"Beginning epoch\", x, end = '\\n\\n')\n",
    "    theta = stochastic_descent(theta, train_labels, train)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qualitative(y, theta, train, labels):\n",
    "    pred = softmax(inference(theta, train[y]))\n",
    "    for i, x in enumerate(pred):\n",
    "        print(i+1, x)\n",
    "    print('prediction:', np.argmax(pred)+1)\n",
    "    print('actual:', int(labels[y]))\n",
    "    print('loss:', loss(pred, labels[y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01416432, 0.0051974 , 0.00449775, ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4164321034889724\n"
     ]
    }
   ],
   "source": [
    "with open('data/training.txt', 'r') as fin:\n",
    "    x = fin.read().splitlines()\n",
    "a = x[0].split(' ')\n",
    "noThe = 0\n",
    "for x in range(len(a)-1):\n",
    "    if a[x] == 'the':\n",
    "        noThe += 1\n",
    "print(noThe/len(a)*math.log(3000/2995)*10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.reshape(train, train.shape[0]*train.shape[1])\n",
    "plt.hist(x, bins = 100, range=[0, .6])\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.reshape(train, train.shape[0]*train.shape[1])\n",
    "plt.hist(x, bins = 100, range=[0, 45])\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
